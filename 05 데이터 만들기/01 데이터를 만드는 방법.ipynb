{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05 데이터 만들기\n",
    "# 0501 데이터를 만드는 방법\n",
    "# 050101 데이터 만들기의 중요성\n",
    "\n",
    "데이터는 하나의 자산이다.\n",
    "회사들이 데이터 공개를 꺼려하는 것은 아주 당연한 현상이다.\n",
    "심지어 데이터를 모아서 매매하는 회사들까지 생겨나고 있다.\n",
    "\n",
    "데이터를 잘 활용하는 회사는 어떤 것이 있을까?\n",
    "패션 브랜드 ZARA는 패션업계에서 수 년째 엄청난 성과를 내고 있으며\n",
    "창업자인 아만시오 오르테가는 한 때 세계 부호 1위에 이름을 올리기도 했습니다.\n",
    "이런 자라의 성공비결은 다름 아닌 데이터입니다.\n",
    "\n",
    "자라는 어떤 데이터를 분석했을까요. 우선은 가장 뻔한 몇가지가 있습니다.\n",
    "매장에서 판매되고 환불되는 데이터도 있을 것이고,\n",
    "웹사이트나 SNS에서 활동하는 유저들의 데이터도 있을 것이고,\n",
    "설문조사 데이터도 있을 것입니다.\n",
    "그런데 자라는 여기서 멈추지 않았습니다.\n",
    "\n",
    "전세계 자라의 직원들은 고객들에게 끊임없이 질문하며 커뮤니케이션을 유도하고\n",
    "그 결과를 모두 PDA에 기록해 데이터 분석에 활용하였고\n",
    "심지어 옷에 붙어있는 TAG에 작은 칩을 달아놓아 손님들이 그 옷을 가지고 피팅룸에 얼마나 많이 왔다갔다 하는지도 기록하였습니다.\n",
    "아마도 이 외에 더 멋있고 화려하게 데이터 분석을 하고 있을 겁니다.\n",
    "\n",
    "자라는 이런 데이터 활용의 결과\n",
    "- 디자인부터 매장 입고까지의 시간 단축\n",
    "    압도적인 양의 디자인을 말도 안 되는 빠른 시간 안에 생산해내고\n",
    "- 효율적인 재고 관리\n",
    "    재고도 효율적으로 관리할 수 있었습니다.\n",
    "\n",
    "자라의 가장 큰 경쟁력은 데이터를 분석하기 전에\n",
    "우선 무수한 양의 데이터를 모으는 것에 있을 겁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 050102 데이터 다운로드 받기\n",
    "데이터를 구하는 가장 쉬운 방법은, 이미 누군가 만들어둔 데이터를 사용하는 것입니다.\n",
    "대표적으로, 국가 기관에서는 공익 목적으로 여러 데이터를 공개합니다.\n",
    "그 외에도 데이터를 검색하는 사이트나, 데이터를 공유하는 사이트들이 있습니다.\n",
    "\n",
    "국내 사이트\n",
    "서울열린데이터광장  https://data.seoul.go.kr/\n",
    "공공데이터포털  https://www.data.go.kr\n",
    "e-나라지표  http://www.index.go.kr/\n",
    "국가통계포털  http://kosis.kr\n",
    "서울특별시 빅데이터 캠퍼스  https://bigdata.seoul.go.kr/\n",
    "통계청  http://kostat.go.kr/\n",
    "    \n",
    "각 사이트를 보면, 여러 분야의 데이터를 다운로드 받을 수 있습니다.\n",
    "혹은 원하는 데이터를 신청하면 제공해주기도 합니다.\n",
    "\n",
    "해외 사이트\n",
    "구글 데이터 검색  https://toolbox.google.com/datasetsearch\n",
    "캐글  https://www.kaggle.com/datasets\n",
    "Awesome Public Datasets Github  https://github.com/awesomedata/awesome-public-datasets\n",
    "Data and Story Library  https://dasl.datadescription.com/\n",
    "데이터허브  https://datahub.io/\n",
    "\n",
    "구글 등의 검색 엔진을 활용하면, 더 다양한 데이터를 찾을 수 있습니다.\n",
    "하지만 데이터에 저작권이 잇기도 하니, 실제로 데이터를 활용할 때는 잘 확인하고 사용하셔야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 050103 센서 사용하기\n",
    "\n",
    "센서(Sensor) : 물리적인 현상을 감지해서 전기 신호로 변환해 주는 장치\n",
    "예를 들어 방에 사람이 들어가면 불이 커지고 사람이 나오면 불이 꺼지는 전등도 센서를 활요한 것입니다.\n",
    "세상에 수없이 존재하는 센서로 데이터를 모을 수도 있습니다.\n",
    "예를 들어 에스컬레이터에 센서를 달아두어 언제 어디서 사람들이 에스컬레이터를 많이 이용하는지 알 수 있습니다.\n",
    "\n",
    "일반 개발자들도 아두이노(Arduino)나 라즈베리 파이(Raspberry Pi)등을 사용하면 센서로 데이터를 모을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 050104 웹에서 모으기\n",
    "\n",
    "가장 빠르게 데이터가 쌓이는 곳? : 인터넷\n",
    "사람들은 컴퓨터와 스마트폰과 함께하는 시간이 많기 때문에 자연스럽게 인터넷에 많은 데이터가 모일 수밖에 없습니다.\n",
    "\n",
    "우리도 서비스를 만들면 데이터를 모을 수 있습니다. 하지만 서비스를 만든다는 것은 어려운 일입니다.\n",
    "\n",
    "기본적으로 회사들은 데이터를 꽁꽁 숨기지만 사실 공개된 데이터도 많습니다.\n",
    "\n",
    "웹에 있는 데이터를 수집할 때 주로 사용하는 용어로는 웹 스크레이핑과 웹 크롤링이 있습니다.\n",
    "\n",
    "웹 스크레이핑(Web Scraping)은 하나의 페이지에서 원하는 정보를 가져오는 것을 의미합니다.\n",
    "웹 스크레이핑을 하기 위해서는 우선 웹 페이지가 필요합니다.\n",
    "웹 페이지는 우리가 하나하나 수집해야하지만 프로그래밍을 이용해서 컴퓨터가 자동으로 웹 페이지를 가져오도록 할 수 있습니다.\n",
    "웹 크롤링(Web Crawling)은 프로그래밍으로 웹 페이지를 자동으로 가져오는 바로 그 행위를 가리키고 이 프로그램을 웹 크롤러라고 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
